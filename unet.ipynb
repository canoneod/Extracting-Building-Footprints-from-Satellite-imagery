{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "spacenet_datapreprocess_unet_ver1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# installing required libraries\r\n",
        "!pip install geopandas\r\n",
        "!add-apt-repository ppa:ubuntugis/ppa -y\r\n",
        "!apt-get update\r\n",
        "!apt-get install python-numpy gdal-bin libgdal-dev python3-rtree\r\n",
        "!pip install rasterio"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e94lep0vlXYm",
        "outputId": "633e3c58-4c2d-4a3b-a937-6a7637a0906b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.backends.cudnn as cudnn\r\n",
        "import torch.optim as optim\r\n",
        "import os\r\n",
        "\r\n",
        "\r\n",
        "%matplotlib inline\r\n",
        "%config InlineBackend.figure_format = 'retina'\r\n",
        "import skimage\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "%cd /content/gdrive/MyDrive/SpaceNet\r\n",
        "import libs.solaris as sol # modified solaris library\r\n",
        "from utils.dist import *\r\n",
        "from data.dataset import *\r\n",
        "from models.unet import *\r\n",
        "from glob import glob"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KV_-xu50RTD",
        "outputId": "ed8940b3-5789-440e-a3ee-3fc11d82e77a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# load data and define transform\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "\r\n",
        "dataset = Spacenet()\r\n",
        "\r\n",
        "train, test = torch.utils.data.random_split(dataset, [int(len(dataset)*0.8), len(dataset) - int(len(dataset)*0.8)])\r\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size = 12, shuffle=True, num_workers=2)\r\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size= 12, shuffle=True, num_workers=2)"
      ],
      "outputs": [],
      "metadata": {
        "id": "ReUPQ1AZz0pX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# baseline model\r\n",
        "device = 'cuda'\r\n",
        "\r\n",
        "net = Unet(8, 2)\r\n",
        "net = net.to(device)\r\n",
        "#cudnn.benchmark = True\r\n",
        "\r\n",
        "file_name = 'Unet_khartoum.pt'\r\n",
        "trained_dir = '/content/gdrive/MyDrive/SpaceNet/trained'\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss() \r\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0001, weight_decay = 0.1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "xJ8s4CII9QfJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# train and evaluate\r\n",
        "from utils.eval import *\r\n",
        "import math\r\n",
        "val_loss = []\r\n",
        "\r\n",
        "def train(epoch):\r\n",
        "  print('\\n Current train epoch : ', epoch)\r\n",
        "  net.train()\r\n",
        "  for batch_idx, (imgs, targets) in enumerate(train_loader):\r\n",
        "    imgs, targets = imgs.to(device), targets.to(device)\r\n",
        "    optimizer.zero_grad()\r\n",
        "    outputs = net(imgs)\r\n",
        "\r\n",
        "    loss = criterion(outputs, targets)\r\n",
        "  \r\n",
        "    loss.backward()\r\n",
        "    if math.isnan(loss.item()):\r\n",
        "      raise KeyboardInterrupt('nan detected')\r\n",
        "    print('loss: ', loss.item())\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "def test(epoch):\r\n",
        "  print('\\n current validation epoch: ', epoch)\r\n",
        "  net.eval()\r\n",
        "  total_loss = 0\r\n",
        "  for batch_idx, (imgs, targets) in enumerate(validation_loader):\r\n",
        "    imgs, targets = imgs.to(device), targets.to(device)\r\n",
        "    optimizer.zero_grad()\r\n",
        "    outputs = net(imgs)\r\n",
        "\r\n",
        "    loss = criterion(outputs, targets)\r\n",
        "    total_loss += loss.item()/10 # divide by batch size \r\n",
        "\r\n",
        "  state = {\r\n",
        "      'net': net.state_dict(),\r\n",
        "      'epoch': epoch,\r\n",
        "      'optimizer': optimizer.state_dict()\r\n",
        "  }\r\n",
        "  torch.save(state, os.path.join(trained_dir, file_name))\r\n",
        "  val_loss.append(total_loss)\r\n",
        "  print('\\n Current loss : ', total_loss) # get segmentation metrics "
      ],
      "outputs": [],
      "metadata": {
        "id": "ejjF1UVFEjud"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for epoch in range(1, 60):\r\n",
        "  train(epoch)\r\n",
        "  test(epoch)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KqCcSKHtQ5G",
        "outputId": "bfdf6068-6ad5-4912-b754-497642d2119b"
      }
    }
  ]
}